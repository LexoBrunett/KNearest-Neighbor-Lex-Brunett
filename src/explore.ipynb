{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m total_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/4GeeksAcademy/decision-tree-project-tutorial/main/diabetes.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m total_data \u001b[38;5;241m=\u001b[39m total_data\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mreset_index(drop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/k-nearest-neighbors-project-tutorial/main/tmdb_5000_movies.csv\")\n",
    "credits = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/k-nearest-neighbors-project-tutorial/main/tmdb_5000_credits.csv\")\n",
    "\n",
    "movies.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"../data/movies_database.db\")\n",
    "\n",
    "movies.to_sql(\"movies_table\", conn, if_exists = \"replace\", index = False)\n",
    "credits.to_sql(\"credits_table\", conn, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge tables for creating a new DataFrame\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM movies_table\n",
    "    INNER JOIN credits_table\n",
    "    ON movies_table.title = credits_table.title;\n",
    "\"\"\"\n",
    "\n",
    "total_data = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "total_data = total_data.loc[:, ~total_data.columns.duplicated()]\n",
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transform as expected\n",
    "import json\n",
    "\n",
    "def load_json_safe(json_str, default_value = None):\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except (TypeError, json.JSONDecodeError):\n",
    "        return default_value\n",
    "    \n",
    "total_data[\"genres\"] = total_data[\"genres\"].apply(lambda x: [item[\"name\"] for item in json.loads(x)] if pd.notna(x) else None)\n",
    "total_data[\"keywords\"] = total_data[\"keywords\"].apply(lambda x: [item[\"name\"] for item in json.loads(x)] if pd.notna(x) else None)\n",
    "\n",
    "total_data[\"cast\"] = total_data[\"cast\"].apply(lambda x: [item[\"name\"] for item in json.loads(x)][:3] if pd.notna(x) else None)\n",
    "\n",
    "total_data[\"crew\"] = total_data[\"crew\"].apply(lambda x: \" \".join([crew_member['name'] for crew_member in load_json_safe(x) if crew_member['job'] == 'Director']))\n",
    "\n",
    "total_data[\"overview\"] = total_data[\"overview\"].apply(lambda x: [x])\n",
    "\n",
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data[\"overview\"] = total_data[\"overview\"].apply(lambda x: [str(x)])\n",
    "total_data[\"genres\"] = total_data[\"genres\"].apply(lambda x: [str(genre) for genre in x])\n",
    "total_data[\"keywords\"] = total_data[\"keywords\"].apply(lambda x: [str(keyword) for keyword in x])\n",
    "total_data[\"cast\"] = total_data[\"cast\"].apply(lambda x: [str(actor) for actor in x])\n",
    "total_data[\"crew\"] = total_data[\"crew\"].apply(lambda x: [str(crew_member) for crew_member in x])\n",
    "\n",
    "total_data[\"tags\"] = total_data[\"overview\"] + total_data[\"genres\"] + total_data[\"keywords\"] + total_data[\"cast\"] + total_data[\"crew\"]\n",
    "total_data[\"tags\"] = total_data[\"tags\"].apply(lambda x: \",\".join(x).replace(\",\", \" \"))\n",
    "\n",
    "total_data.drop(columns = [\"genres\", \"keywords\", \"cast\", \"crew\", \"overview\"], inplace = True)\n",
    "\n",
    "total_data.iloc[0].tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.to_csv(\"../data/processed/clean_data.csv\", index = False)\n",
    "\n",
    "conn = sqlite3.connect(\"../data/movies_database.db\")\n",
    "\n",
    "movies.to_sql(\"clean_movies_data\", conn, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN modeling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(total_data[\"tags\"])\n",
    "\n",
    "model = NearestNeighbors(n_neighbors = 6, algorithm = \"brute\", metric = \"cosine\")\n",
    "model.fit(tfidf_matrix)\n",
    "\n",
    "def get_movie_recommendations(movie_title):\n",
    "    movie_index = total_data[total_data[\"title\"] == movie_title].index[0]\n",
    "    distances, indices = model.kneighbors(tfidf_matrix[movie_index])\n",
    "    similar_movies = [(total_data[\"title\"][i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
    "    return similar_movies[1:]\n",
    "\n",
    "input_movie = \"How to Train Your Dragon\"\n",
    "recommendations = get_movie_recommendations(input_movie)\n",
    "print(\"Film recommendations '{}'\".format(input_movie))\n",
    "for movie, distance in recommendations:\n",
    "    print(\"- Film: {}\".format(movie))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
